{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0aeefeb",
   "metadata": {},
   "source": [
    "# Neural Nets\n",
    "In this notebook, I will use 'loan_data' to implement Neural Nets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518905fe",
   "metadata": {},
   "source": [
    "### Load necessary libraries and data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d93c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangdameinv/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e99ce867",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('loan_data.csv')\n",
    "cat_feats = ['purpose']\n",
    "final_data = pd.get_dummies(loans,columns=cat_feats,drop_first=True)\n",
    "final_data.head()\n",
    "X = final_data.drop('not.fully.paid',axis=1)\n",
    "y = final_data['not.fully.paid']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "549fbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.Series(y_train)\n",
    "y_train = y_train.values.reshape(-1, 1)\n",
    "y_test=pd.Series(y_test)\n",
    "y_test = y_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ecc6ba",
   "metadata": {},
   "source": [
    "### Let's define the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbbbd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/w3cqlkc16gx52552_9pn4hzh0000gn/T/ipykernel_5667/3525442033.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.13259268294131815\n",
      "Epoch 100, Loss: 0.08129474940266469\n",
      "Epoch 200, Loss: 0.08129474940266469\n",
      "Epoch 300, Loss: 0.08129474940266469\n",
      "Epoch 400, Loss: 0.08129474940266469\n",
      "Epoch 500, Loss: 0.08129474940266469\n",
      "Epoch 600, Loss: 0.08129474940266469\n",
      "Epoch 700, Loss: 0.08129474940266469\n",
      "Epoch 800, Loss: 0.08129474940266469\n",
      "Epoch 900, Loss: 0.08129474940266469\n",
      "Final Predictions: [1.55748195e-13 1.21330073e-11 1.55748195e-13 ... 1.21330073e-11\n",
      " 1.21330073e-11 1.55748195e-13]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 18\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "biases_hidden = np.zeros((1, hidden_size))\n",
    "weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "biases_output = np.zeros((1, output_size))\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    hidden_layer_input = np.dot(X_train, weights_input_hidden) + biases_hidden\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Compute loss (mean squared error)\n",
    "    loss = np.mean(0.5 * (predicted_output - y_train)**2)\n",
    "\n",
    "    # Backward pass\n",
    "    output_error = predicted_output - y_train\n",
    "    output_delta = output_error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    hidden_layer_error = output_delta.dot(weights_hidden_output.T)\n",
    "    hidden_layer_delta = hidden_layer_error * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Update weights and biases using gradient descent\n",
    "    weights_hidden_output -= learning_rate * hidden_layer_output.T.dot(output_delta)\n",
    "    biases_output -= learning_rate * np.sum(output_delta, axis=0, keepdims=True)\n",
    "\n",
    "    weights_input_hidden -= learning_rate * X_train.T.dot(hidden_layer_delta)\n",
    "    biases_hidden -= learning_rate * np.sum(hidden_layer_delta, axis=0, keepdims=True)\n",
    "\n",
    "    # Print the loss for every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Make predictions with the trained model\n",
    "final_hidden_layer_input = np.dot(X_train, weights_input_hidden) + biases_hidden\n",
    "final_hidden_layer_output = sigmoid(final_hidden_layer_input)\n",
    "final_output_layer_input = np.dot(final_hidden_layer_output, weights_hidden_output) + biases_output\n",
    "final_predicted_output = sigmoid(final_output_layer_input)\n",
    "\n",
    "# Print the final predictions\n",
    "print(\"Final Predictions:\", final_predicted_output.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2bc88f",
   "metadata": {},
   "source": [
    "### Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7b9bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training data set: 0.8374105011933174\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean((final_predicted_output > 0.5) == y_train)\n",
    "print(\"Accuracy of training data set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12516b70",
   "metadata": {},
   "source": [
    "### The performance in testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35b96ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ss/w3cqlkc16gx52552_9pn4hzh0000gn/T/ipykernel_5667/3525442033.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07707028531391885\n",
      "Epoch 100, Loss: 0.07707028531391885\n",
      "Epoch 200, Loss: 0.07707028531391885\n",
      "Epoch 300, Loss: 0.07707028531391885\n",
      "Epoch 400, Loss: 0.07707028531391885\n",
      "Epoch 500, Loss: 0.07707028531391885\n",
      "Epoch 600, Loss: 0.07707028531391884\n",
      "Epoch 700, Loss: 0.07707028531391884\n",
      "Epoch 800, Loss: 0.07707028531391884\n",
      "Epoch 900, Loss: 0.07707028531391884\n",
      "Final Predictions: [1.55748239e-13 1.55748239e-13 1.21330107e-11 ... 1.21330107e-11\n",
      " 1.21330107e-11 6.62398120e-12]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    hidden_layer_input = np.dot(X_test, weights_input_hidden) + biases_hidden\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Compute loss (mean squared error)\n",
    "    loss = np.mean(0.5 * (predicted_output - y_test)**2)\n",
    "\n",
    "    # Backward pass\n",
    "    output_error = predicted_output - y_test\n",
    "    output_delta = output_error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    hidden_layer_error = output_delta.dot(weights_hidden_output.T)\n",
    "    hidden_layer_delta = hidden_layer_error * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Update weights and biases using gradient descent\n",
    "    weights_hidden_output -= learning_rate * hidden_layer_output.T.dot(output_delta)\n",
    "    biases_output -= learning_rate * np.sum(output_delta, axis=0, keepdims=True)\n",
    "\n",
    "    weights_input_hidden -= learning_rate * X_test.T.dot(hidden_layer_delta)\n",
    "    biases_hidden -= learning_rate * np.sum(hidden_layer_delta, axis=0, keepdims=True)\n",
    "\n",
    "    # Print the loss for every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Make predictions with the trained model\n",
    "final_hidden_layer_input = np.dot(X_test, weights_input_hidden) + biases_hidden\n",
    "final_hidden_layer_output = sigmoid(final_hidden_layer_input)\n",
    "final_output_layer_input = np.dot(final_hidden_layer_output, weights_hidden_output) + biases_output\n",
    "final_predicted_output = sigmoid(final_output_layer_input)\n",
    "\n",
    "# Print the final predictions\n",
    "print(\"Final Predictions:\", final_predicted_output.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c473d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing data set: 0.8458594293667363\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean((final_predicted_output > 0.5) == y_test)\n",
    "print(\"Accuracy of testing data set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
